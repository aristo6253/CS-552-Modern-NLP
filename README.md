# CS-552: Modern-NLP

## Exercise Set 1

### Word Embeddings

**What?**<br>A learned representation for text (words with similar meaning have similar representations).

**How?**<br>There are multiple ways (e.g. focus on neighboring words, derive relationships...)

- **Word2Vec:** Uses shallow NN to learn word vectors.

- **GloVe:** Word relationships can be recovered from the co-occurence matrix of any large enough corpus.